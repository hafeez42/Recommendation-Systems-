{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Content Recommender System.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPANUWWL9DYcJBzQ6EUve45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafeez42/Recommendation-Systems-/blob/main/Basic_Content_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtNvI4Ct5SJW",
        "outputId": "1948471a-ecb0-4b9d-81a4-95e938d8530b"
      },
      "source": [
        "!pip install tensorflow==2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.5\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.1.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.4.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 14.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.17.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.37.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.12.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (3.6.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68725 sha256=e933b2257a4b6463a71641ed4df3426dedd12a56815b22a391c06bb85dda94f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, wrapt, tensorflow-estimator, keras-nightly, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.1\n",
            "    Uninstalling grpcio-1.41.1:\n",
            "      Successfully uninstalled grpcio-1.41.1\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed flatbuffers-1.12 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGCr9xif6T3q",
        "outputId": "1b5c1bbf-df52-4445-8b45-e2592b7ea315"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe5bg1Ns9vks"
      },
      "source": [
        "To start, we'll create our list of users, movies and features. While the users and movies represent elements in our database, for a content-based filtering method the features of the movies are likely hand-engineered and rely on domain knowledge to provide the best embedding space. Here we use the categories of Action, Sci-Fi, Comedy, Cartoon, and Drama to describe our movies (and thus our users).\n",
        "\n",
        "In this example, we will assume our database consists of four users and six movies, listed below.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEfIGRVT7kWt"
      },
      "source": [
        "users = ['Ryan', 'Danielle',  'Vijay', 'Chris']\n",
        "movies = ['Star Wars', 'The Dark Knight', 'Shrek', 'The Incredibles', 'Bleu', 'Memento']\n",
        "features = ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
        "\n",
        "num_users = len(users)\n",
        "num_movies = len(movies)\n",
        "num_feats = len(features)\n",
        "num_recommendations = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsMl43e57oq5"
      },
      "source": [
        "# each row represents a user's rating for the different movies\n",
        "users_movies = tf.constant([\n",
        "                [4,  6,  8,  0, 0, 0],\n",
        "                [0,  0, 10,  0, 8, 3],\n",
        "                [0,  6,  0,  0, 3, 7],\n",
        "                [10, 9,  0,  5, 0, 2]],dtype=tf.float32)\n",
        "\n",
        "# features of the movies one-hot encoded\n",
        "# e.g. columns could represent ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
        "movies_feats = tf.constant([\n",
        "                [1, 1, 0, 0, 1],\n",
        "                [1, 1, 0, 0, 0],\n",
        "                [0, 0, 1, 1, 0],\n",
        "                [1, 0, 1, 1, 0],\n",
        "                [0, 0, 0, 0, 1],\n",
        "                [1, 0, 0, 0, 1]],dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDyKVGgb8ALv"
      },
      "source": [
        "### Computing the user feature matrix\n",
        "\n",
        "We will compute the user feature matrix; that is, a matrix containing each user's embedding in the five-dimensional feature space. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDnasHuw7uNg",
        "outputId": "2a43ad21-464b-44e6-c856-b21ad7bfc480"
      },
      "source": [
        "users_feats = tf.matmul(users_movies,movies_feats)\n",
        "users_feats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[10., 10.,  8.,  8.,  4.],\n",
              "       [ 3.,  0., 10., 10., 11.],\n",
              "       [13.,  6.,  0.,  0., 10.],\n",
              "       [26., 19.,  5.,  5., 12.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM1pUp8P8DY7"
      },
      "source": [
        "Next we normalize each user feature vector to sum to 1. Normalizing isn't strictly neccesary, but it makes it so that rating magnitudes will be comparable between users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqc7p7yq7zRp",
        "outputId": "fc967d72-1acf-4687-916e-4a5d9759cc4a"
      },
      "source": [
        "users_feats = users_feats/tf.reduce_sum(users_feats,axis=1,keepdims=True)\n",
        "users_feats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[0.25      , 0.25      , 0.2       , 0.2       , 0.1       ],\n",
              "       [0.0882353 , 0.        , 0.29411766, 0.29411766, 0.32352942],\n",
              "       [0.44827586, 0.20689656, 0.        , 0.        , 0.3448276 ],\n",
              "       [0.3880597 , 0.2835821 , 0.07462686, 0.07462686, 0.17910448]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG21LJYa9IUr"
      },
      "source": [
        "#### Ranking feature relevance for each user\n",
        "\n",
        "We can use the users_feats computed above to represent the relative importance of each movie category for each user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnmcumZg9JLf",
        "outputId": "25b606f0-2798-45ba-8d51-9fa6bf22330d"
      },
      "source": [
        "top_users_features = tf.nn.top_k(users_feats, num_feats)[1]\n",
        "top_users_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=int32, numpy=\n",
              "array([[0, 1, 2, 3, 4],\n",
              "       [4, 2, 3, 0, 1],\n",
              "       [0, 4, 1, 2, 3],\n",
              "       [0, 1, 4, 2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHSLFIWT76Jp",
        "outputId": "2e8b8090-c0eb-4b31-e0e5-04c4a812d6e8"
      },
      "source": [
        "for i in range(num_users):\n",
        "    feature_names = [features[int(index)] for index in top_users_features[i]]\n",
        "    print('{}: {}'.format(users[i],feature_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ryan: ['Action', 'Sci-Fi', 'Comedy', 'Cartoon', 'Drama']\n",
            "Danielle: ['Drama', 'Comedy', 'Cartoon', 'Action', 'Sci-Fi']\n",
            "Vijay: ['Action', 'Drama', 'Sci-Fi', 'Comedy', 'Cartoon']\n",
            "Chris: ['Action', 'Sci-Fi', 'Drama', 'Comedy', 'Cartoon']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634cfmnx9Ul_"
      },
      "source": [
        "### Determining movie recommendations. \n",
        "\n",
        "We'll now use the `users_feats` tensor we computed above to determine the movie ratings and recommendations for each user.\n",
        "\n",
        "To compute the projected ratings for each movie, we compute the similarity measure between the user's feature vector and the corresponding movie feature vector.  \n",
        "\n",
        "We will use the dot product as our similarity measure. In essence, this is a weighted movie average for each user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfNd2DtA9P8B",
        "outputId": "4af1a747-d6ef-4c07-818c-39216d6b6df7"
      },
      "source": [
        "users_ratings = tf.matmul(users_feats,tf.transpose(movies_feats))\n",
        "users_ratings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
              "array([[0.6       , 0.5       , 0.4       , 0.65      , 0.1       ,\n",
              "        0.35      ],\n",
              "       [0.4117647 , 0.0882353 , 0.5882353 , 0.67647064, 0.32352942,\n",
              "        0.4117647 ],\n",
              "       [1.        , 0.6551724 , 0.        , 0.44827586, 0.3448276 ,\n",
              "        0.79310346],\n",
              "       [0.8507463 , 0.6716418 , 0.14925373, 0.53731346, 0.17910448,\n",
              "        0.5671642 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5c7KGBe9cde"
      },
      "source": [
        "The computation above finds the similarity measure between each user and each movie in our database. To focus only on the ratings for new movies, we apply a mask to the all_users_ratings matrix.  \n",
        "\n",
        "If a user has already rated a movie, we ignore that rating. This way, we only focus on ratings for previously unseen/unrated movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e-LxC0q9YXo",
        "outputId": "f7f72bf7-b9ff-4966-ad7c-a0eb5068188f"
      },
      "source": [
        "users_ratings_new = tf.where(tf.equal(users_movies, tf.zeros_like(users_movies)),\n",
        "                                  users_ratings,\n",
        "                                  tf.zeros_like(tf.cast(users_movies, tf.float32)))\n",
        "users_ratings_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 6), dtype=float32, numpy=\n",
              "array([[0.        , 0.        , 0.        , 0.65      , 0.1       ,\n",
              "        0.35      ],\n",
              "       [0.4117647 , 0.0882353 , 0.        , 0.67647064, 0.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.44827586, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.14925373, 0.        , 0.17910448,\n",
              "        0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrA6G0Pq9kQ8"
      },
      "source": [
        "Finally let's grab and print out the top 2 rated movies for each user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pwGE-Rr9bMh",
        "outputId": "76b80c8e-5918-44b4-a028-4efd67831739"
      },
      "source": [
        "top_movies = tf.nn.top_k(users_ratings_new, num_recommendations)[1]\n",
        "top_movies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
              "array([[3, 5],\n",
              "       [3, 0],\n",
              "       [0, 3],\n",
              "       [4, 2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFaoyoPl9nBR",
        "outputId": "6f9ef851-4929-49a2-c950-c23c38f840fe"
      },
      "source": [
        "for i in range(num_users):\n",
        "    movie_names = [movies[index] for index in top_movies[i]]\n",
        "    print('{}: {}'.format(users[i],movie_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ryan: ['The Incredibles', 'Memento']\n",
            "Danielle: ['The Incredibles', 'Star Wars']\n",
            "Vijay: ['Star Wars', 'The Incredibles']\n",
            "Chris: ['Bleu', 'Shrek']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2D75Qp69pUh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}